# Bonus Track 

## AI is a double-edged Technology

### Text to Speech Generation

**Good application** was the use of AI to generate speech in a language you're not fluent in - the AI both translates the text and generates speech to sound like you.

Example of the Indian Election - there are so many dialects that poiticians used text to speech to create campaign broadcasts in multiple languages (including those they weren't fluent in) with their own cloned voice.

Interestingly, Karthik had been in India during the Election campaign and said there was a lot of disinformation generated by AI!

**Harmful application** is the use of voice cloning to scam victims - particularly nasty examples of targeting the elderly for fraud.

What's new here? AI lowers the barrieir to entry for fraudsters.

### Audio Book Narrators

AI generated audio could see people replaced by AI - a good example being Audio Book narrators.

Humans are probably still better - they read the whole book and they probably are more nuanced at present - for the most popular titles we'll probably still have professional human narrators.

But for the long tail of content, AI generated audio books are good enough where it is not economic to pay a human.

## AI augments human ability or takes away jobs?

### What is the value of the human element?

Example of disaster where a company replaced people with chatbots for help line.

The advent of MOOCs 10 years ago was threatening to disrupt education - would there be an end to Colleges? In the best cases, there is enduring value in the insights from a Professor and the opportunity to be able to talk to the instructor.

### Key observation by Economists

- _Jobs are bundles of tasks_
- _AI automates tasks_

It is hard to predict how the automation of tasks will affect different jobs.

Depends also on how we choose to use AI.

### Generative AI's Killer Application - Software Code Generation

Example of **GitHub CoPilot** (see our Meetup's last in-person Tech Talk!)

If it is easier and quicker to verify the generated software code, then there is definitely a productivity gain.

Pair Programming with a digitial assistant is the best example of **Co-Intelligence** (see Etham Mollick's book).

However, anecdotal evidence suggests **CoPilot** and other AI assistants generate code with baked in software vulnerabilities due to errors in the training data or is unable to generate working code for niche specialist libraries (the case where they could add most value).

My personal view is that digital assistants for code generation is a good use case when you pair program and you use it for boiler plate code and to generate automatic tests.

I'm skeptical about full automation at the present time - I think software code generation is an area where AI augments domain experts - but who knows?

DeepLearning.AI have developed a Python course for beginners that assumes you'll use a digitial assistant from scratch as you learn the language.

## AI, Policy and Society

This is the subject area the book is trying to develop a narrative for and to influence - and, in my view, it's an area where there is a lot of ill-informed assertion and poor scholarship ...

## Hallucinations

Great examples of chatbot generating bogus references for papers that were never written - bogus citations.

_The surprise should be that they generate correct results_

LLMs - the underlying tech for chatbots - generate the next token in a long sequence: how do these _stochastic parrots_ ever come up with correct results!

Nice example of asking a chatbot for both author's most prominant academic paper:

- Sayesh reference was entirely made up: hallucination!
- Arvind citation was entirely correct

Arvind's paper was decades old and had been written about many times - it was memorized in the training data.

### Mitigating Hallucinations

- Retrieve real-time information at the point of query
- Pre-trained knowledge compared or combined with real-time information
- Introduce _guardrails_ on the output

### Form is no longer a Proxy for Correctness

In the past, you could look at the form of something to see if it was legitimate.

_In the Age of Generative AI, you can no longer rely on the form of something as a proxy for whether it is correct or not._

Great example of lawyers filing fake citations

## BIG TECH

Big Tech reaps the reward (automation, scale, cost reduction) and society bears the consequences (...).

## AI Snake Oil website

The authors maintain a website[^AISnakeOilWebSite] for the book containing Blogs and Supplementary materials, including exercises and discussion notes[^AISnakeOilExercises].

## REFERENCES

[^AISnakeOilWebSite]:
    https://www.aisnakeoil.com/ - "Debunking AI hype. The book gives you foundational knowledge and the newsletter covers new developments."

[^AISnakeOilExercises]:	
	https://www.aisnakeoil.com/p/ai-snake-oil-exercises-and-discussion
 










